{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio.transforms import Resample\n",
    "\n",
    "# fixed-point conversion function\n",
    "def to_fixed_point(tensor, int_bits, frac_bits):\n",
    "    scale_factor = 2 ** frac_bits\n",
    "    max_value = (2 ** (int_bits - 1)) - 1 / scale_factor\n",
    "    min_value = -(2 ** (int_bits - 1))\n",
    "    \n",
    "    # Round and clamp all values in the tensor at once\n",
    "    tensor_fp = torch.round(tensor * scale_factor)\n",
    "    tensor_fp = torch.clamp(tensor_fp, min_value * scale_factor, max_value * scale_factor)\n",
    "    return tensor_fp / scale_factor\n",
    "\n",
    "def preprocess_and_save(file_path, target_sample_rate, int_bits, frac_bits, raw_root, preprocessed_root):\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resampler = Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "    \n",
    "    waveform_fp = to_fixed_point(waveform, int_bits, frac_bits)\n",
    "    \n",
    "    relative_path = os.path.relpath(file_path, raw_root)\n",
    "    save_path = os.path.join(preprocessed_root, relative_path)\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    \n",
    "    torchaudio.save(save_path, waveform_fp, target_sample_rate)\n",
    "\n",
    "# maintain folder structure\n",
    "def preprocess_dataset(raw_root, preprocessed_root, target_sample_rate, int_bits, frac_bits):\n",
    "    for dirpath, _, filenames in os.walk(raw_root):\n",
    "        for filename in filenames:\n",
    "            if filename.lower().endswith(('.wav', '.flac')):  \n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                preprocess_and_save(file_path, target_sample_rate, int_bits, frac_bits, raw_root, preprocessed_root)\n",
    "\n",
    "for NUM_SOURCES in range(2, 5):\n",
    "    raw_data_root = f'G:\\\\Jupyter\\\\SoundMixer\\\\{NUM_SOURCES}Speakers5KHalf'\n",
    "    preprocessed_data_root = f'{NUM_SOURCES}Speakers5KHalfPreprocessed'\n",
    "    target_sample_rate = 8000\n",
    "    int_bits = 4\n",
    "    frac_bits = 10\n",
    "\n",
    "    preprocess_dataset(raw_data_root, preprocessed_data_root, target_sample_rate, int_bits, frac_bits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
